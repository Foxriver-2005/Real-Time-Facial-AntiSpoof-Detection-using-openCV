{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6dafa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 12:13:41.367613: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-18 12:13:41.407561: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-18 12:13:41.407601: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-18 12:13:41.408688: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-18 12:13:41.414876: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-18 12:13:41.415587: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-18 12:13:42.493739: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "from cvzone.FaceDetectionModule import FaceDetector\n",
    "from time import time\n",
    "import cvzone\n",
    "import cv2\n",
    "\n",
    "########### PARAMETERS ###########\n",
    "classID = 1 # 0 is fake and 1 is real\n",
    "outputFolderPath = 'Dataset/DataCollect'\n",
    "confidence = 0.8\n",
    "blurThreshold = 100 # large is more focus\n",
    "save = False\n",
    "\n",
    "debug = True\n",
    "offsetPercentageW = 10\n",
    "offsetPercentageH = 20\n",
    "camWidth, camHeight = 640, 480\n",
    "floatingPoint = 6\n",
    "######################\n",
    "#cap = cv2.VideoCapture(\"http://192.168.43.195:8080/video\")\n",
    "cap = cv2.VideoCapture(2)\n",
    "cap.set(3,camWidth)\n",
    "cap.set(4,camHeight)\n",
    "#cap.set(10,150)\n",
    "\n",
    "detector = FaceDetector()\n",
    "\n",
    "while True:\n",
    "    success,img = cap.read()\n",
    "    #img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "    #img = cv2.resize(img, (480, 640))\n",
    "    imgOut = img.copy()\n",
    "    img,bboxs = detector.findFaces(img, draw = False)\n",
    "    \n",
    "    listBlur = []  # True, False values indicating if the faces are blur or not\n",
    "    listInfo = []  # The normalized values and the class name for the label text file\n",
    "    if bboxs:\n",
    "        #Bounding box info: \"id\",\"bbox\",\"score\",\"center\"\n",
    "        for bbox in bboxs:\n",
    "            x, y, w, h = bbox[\"bbox\"]\n",
    "            score = bbox[\"score\"][0]\n",
    "            #print(x,y,w,h)\n",
    "            \n",
    "            #........ Check the score that it is human face ......#\n",
    "            if score > confidence:\n",
    "                #........ Adding offset to face detected ......#\n",
    "                offsetW = (offsetPercentageW / 100) * w\n",
    "                x = int(x - offsetW)\n",
    "                w = int(w + offsetW * 2)\n",
    "                offsetH = (offsetPercentageH / 100) * h\n",
    "                y = int(y - offsetH * 3)\n",
    "                h = int(h + offsetH * 3.5)\n",
    "\n",
    "                #........ To avoid values below zero ......#\n",
    "                if x < 0: x = 0\n",
    "                if y < 0: y = 0\n",
    "                if w < 0: w = 0\n",
    "                if h < 0: h = 0\n",
    "                #........ Finding blurriness in the face detected ......#\n",
    "                imgFace = img[y:y+h,x:x+w]\n",
    "                cv2.imshow(\"Face\",imgFace)\n",
    "                blurValue = int(cv2.Laplacian(imgFace,cv2.CV_64F).var())\n",
    "                if blurValue > blurThreshold:\n",
    "                    listBlur.append(True)\n",
    "                else:\n",
    "                    listBlur.append(False)\n",
    "                \n",
    "                #........ Normalization of values ......#\n",
    "                ih, iw, _ = img.shape\n",
    "                xc, yc = x + w/2, y + h/2\n",
    "                xcn, ycn = round(xc/iw,floatingPoint),round(yc/ih,floatingPoint)\n",
    "                wn, hn = round(w/iw,floatingPoint),round(h/ih,floatingPoint)\n",
    "                #print(xcn,ycn,wn,hn)\n",
    "                \n",
    "                #........ To avoid values above 1 ......#\n",
    "                if xcn > 1: xcn = 1\n",
    "                if ycn > 1: ycn = 1\n",
    "                if wn > 1: wn = 1\n",
    "                if hn > 1: hn = 1\n",
    "                    \n",
    "                listInfo.append(f\"{classID} {xcn} {ycn} {wn} {hn}\\n\")\n",
    "\n",
    "                #........ Drawing ......#\n",
    "                cv2.rectangle(imgOut,(x,y,w,h),(255,0,0),3)\n",
    "                cvzone.putTextRect(imgOut,f'Score:{int(score*100)}% Blur: {blurValue}',(x, y-20),\n",
    "                                  scale=2,thickness=3)\n",
    "                if debug:\n",
    "                    cv2.rectangle(img,(x,y,w,h),(255,0,0),3)\n",
    "                    cvzone.putTextRect(img,f'Score:{int(score*100)}% Blur: {blurValue}',(x, y-20),\n",
    "                                  scale=2,thickness=3)\n",
    "                \n",
    "        #........ To save ......#\n",
    "        if save:\n",
    "            #print(listBlur,all(listBlur))\n",
    "            if all(listBlur) and listBlur != []:\n",
    "                \n",
    "                #........ To save image ......#\n",
    "                timeNow = time()\n",
    "                timeNow = str(timeNow).split('.')\n",
    "                timeNow = timeNow[0] + timeNow[1]\n",
    "                print(timeNow)\n",
    "                cv2.imwrite(f\"{outputFolderPath}/{timeNow}.jpg\",img)\n",
    "                \n",
    "                #........ To save image ......#\n",
    "                for info in listInfo:\n",
    "                    f = open(f\"{outputFolderPath}/{timeNow}.txt\",'a')\n",
    "                    f.write(info)\n",
    "                    f.close()\n",
    "                \n",
    "         \n",
    "    cv2.imshow(\"Image\",imgOut)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b8b871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ba3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
